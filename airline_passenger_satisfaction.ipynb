{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88538c6-a525-4359-8790-4f6180411a0f",
   "metadata": {},
   "source": [
    "# Airline Passenger Satisfaction\n",
    "<img src=\"https://drive.google.com/uc?id=1HvDJElliYQKbdyiCQXsoKdjC8KefRoSL\" alt=\"aitplane in the skies\" style=\"width:500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c8d80f-e94a-4374-8de5-ed9ebe0caf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import ipydatagrid\n",
    "import seaborn as sns\n",
    "import bqplot as bqp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a102e3-8b1e-46cc-84b8-58f7862218bf",
   "metadata": {},
   "source": [
    "## I. Boarding (Introduction/background):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb484c-671c-4e88-b5d6-c6e1f63ac24b",
   "metadata": {},
   "source": [
    "Tired of the constant flight delays? Confused about how to book your flight ticket online? Fed up with the mediocre Food and Drink service offered on-board? Perhaps, on the contrary, you are happy with the comfort of your seat, the spaciousness of the leg room, or the variety of in-flight entertainment provided by your airline. Which of these factor(s) matter to you the most, the consumer?\n",
    "Look no further! We have the answers right here for you!\n",
    "\n",
    "\n",
    "\n",
    "In our analysis of Airline Passenger Satisfaction, we look at various, different variables affecting customer satisfaction, namely Age, Flight Distance, Departure Delay, Arrival Delay, Departure and Arrival Time Convenience, Ease of Online Booking, Check-in Service, Online Boarding, Gate Location, On-board Service, Seat Comfort, Leg Room Service, Cleanliness, Food and Drink, In-flight Service, In-flight Wifi Service, In-flight Entertainment, and Baggage Handling, with the ultimate goal of trying to determine and understand the factors that contribute most to customer satisfaction.\n",
    "In our expedition through Exploratory Data Analysis (EDA), we examine, for example, the different data types and the idiosyncratic nature of our attributes. Utilizing assorted charts and graphs, we can visually analyze the distribution of our dataset and scrutinize closely the relationships among the different variables. By uncovering and interpreting patterns in our dataset during EDA, it will help us understand potential risks or trends the models will create in the Modeling phase. \n",
    "In the Modeling phase, we use a classification model, namely Logistic Regression, to finally make a prediction about the factors that matter most to customer satisfaction. We will consider different logistic regression techniques, compare their results, and use the most effective one for our model. \n",
    "Excited to embark on this data exploratory journey? So are we! Now sit back, relax, and enjoy the flight! Satisfaction guaranteed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2cab90-6418-4de5-a523-4935cd3d3648",
   "metadata": {},
   "source": [
    "Before we “take off” on our data exploration flight, we import our airline_passenger_satisfaction.csv file, which can be located on Kaggle’s website: https://www.kaggle.com/datasets/mysarahmadbhat/airline-passenger-satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f3ab82-9a85-4476-b48b-693b0fbb2e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_df = pd.read_csv(\"airline_passenger_satisfaction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d236f3b-0a9c-4481-8683-028c8cab67d9",
   "metadata": {},
   "source": [
    "## II. Take-Off (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d61e5a-a7f5-46ed-b600-def13c2b9310",
   "metadata": {},
   "source": [
    "Now, as our flight glides on the runway and climbs into the sky of EDA, we take a quick look at the individual features, their Non-Null Count (to discover if there are any NULLs in the dataset), and their data type, which is useful later on when we need to manipulate our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737af51-4aff-40bd-98c4-166eddd82c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick overview of the columns and their types\n",
    "airlines_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3efca80-5a4e-4c88-a430-fc5db207158f",
   "metadata": {},
   "source": [
    "Of course, no data analysis is complete without checking the summary statistics of our dataset. It summarizes the central tendency, dispersion shape of a dataset’s distribution, excluding any NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb5a800-a43f-44c3-9cff-51dcf621c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "airlines_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2291ec2-4f10-48b7-97a2-136021c7a7d0",
   "metadata": {},
   "source": [
    "Earlier, when we looked at the Non-Null Count of each feature, we noticed that the “Arrival Delay column had some NULL values. Let’s look at it using a heatmap!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2a1e4-3cc2-45fe-85db-3c38f892f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NaN values\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.title(\"Null values in the dataset\")\n",
    "ax = sns.heatmap(airlines_df.isna().astype(int), cmap='Blues');\n",
    "ax.set_xlabel(\"Feature\")\n",
    "ax.set_ylabel(\"Row\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c1ae5-b981-4331-a85b-421ec4d44cd1",
   "metadata": {},
   "source": [
    "We sum up all the NULL value for each column and we noticed that there are 393 NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a595ed84-7ec8-464b-abb6-02fd0e51ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330cd73-ba5d-4ca4-b96f-fafa1b09be4a",
   "metadata": {},
   "source": [
    "We look at the “Arrival Delay” column in detail, focusing in on the instances where we have NaN values. Given that we have 393 NULL instances out of 129,880 instances, which is only 0.30%, we decided that the immateriality of the NULL instances warrant dropping those rows altogether so that we can solely focus on the rows with complete information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ae0af5-399f-421c-b32e-21e56db92847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine data with null values\n",
    "airlines_df[airlines_df['Arrival Delay'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38501f04-a37a-4659-bb35-d62722263148",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">Given we have only 393 rows with NaN for Arrival Delay, we can probably drop all NaN rows without much impact on the overall analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b556ff45-c8f5-45ce-a2ea-cfcf382378e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766677f-a1c0-4cf1-8c96-4881eda08f70",
   "metadata": {},
   "source": [
    "Next, as we settle in on our flight, we look at the age distribution by gender. We can see that the distribution of the data between male and female is very similar in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2697c6da-3edf-4722-bcf0-a1db856e6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of ages by gender\n",
    "# plt.title(\"Age distribution by gender\")\n",
    "fig = sns.displot(airlines_df, x='Age', kind='hist', col='Gender', kde=True, height=8, aspect=1)\n",
    "fig.fig.suptitle('Age distribution by gender');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b3416-eb6b-4acf-b028-11ae8132274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age by bracket\n",
    "def get_age_bracket(age):\n",
    "    if age <= 14:\n",
    "        return \"<=14\"\n",
    "    elif age >= 15 and age <= 24:\n",
    "        return \"15-24\"\n",
    "    elif age >=25 and age <= 64:\n",
    "        return \"25-64\"\n",
    "    else:\n",
    "        return \">65\"\n",
    "airlines_df['Age_Bracket'] = airlines_df[\"Age\"].apply(get_age_bracket)\n",
    "sns.displot(airlines_df, x='Age_Bracket', kind='hist', col='Gender', kde=False, height=8, aspect=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d3b20-1de9-4eb8-91e1-a467f798df12",
   "metadata": {},
   "source": [
    "Next, since we were just looking at the count of each gender by age (and by age bracket), we look at the spread for the Satisfaction feature by age. We noticed that there are a lot more younger people who are “Neutral or Dissatisfied” with airlines, while there are slightly more older people who are “Satisfied” with airlines, based on the scores of the various features that were evaluated. \n",
    "We definitely have a lot of work to do in the airline industry to satisfy and appeal to the younger folks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02217bd1-7707-422c-8364-de10d81c3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between satisfaction and age\n",
    "plt.title(\"Satisfaction distribution by age\")\n",
    "sns.boxplot(data=airlines_df, x=\"Satisfaction\", y=\"Age\", palette=\"rainbow\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c2ff19-25a7-4326-9cd8-55d92b321291",
   "metadata": {},
   "source": [
    "We now plot Satisfaction by age bracket, using the same binning strategy as we used above. Using binning allows us to determine that there is actually a lot of work to do for the airline industry across all age brackets when it comes to customer satisfaction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81646e-a16e-4b82-8724-baafc22a899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between satisfaction and age bracket\n",
    "# sns.countplot(data=airlines_df, x=\"Satisfaction\")\n",
    "fig = sns.displot(airlines_df, x='Satisfaction', kind='hist', col='Age_Bracket', kde=False, hue=\"Satisfaction\");\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "fig.fig.suptitle('Satisfaction distribution by age bracket');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15bb0f-8cad-4b2a-9e37-01071a63f132",
   "metadata": {},
   "source": [
    "This plot confirms our understanding: it shows that we have a bit more “Neutral or Dissatisfied” customers than “Satisfied” Customers. But this is still a relatively balanced sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c82509-c6e3-4245-9ad2-ed6a2455acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance between satisfied and unsatisfied customers\n",
    "plt.rcParams['font.size'] = '16'\n",
    "fix, ax = plt.subplots(figsize=(16,9))\n",
    "ax.axes = airlines_df['Satisfaction'].value_counts(normalize=True).plot(kind=\"barh\", color=['salmon', 'dodgerblue'])\n",
    "ax.set_xlabel(\"Percentage of total\")\n",
    "ax.set_ylabel(\"Satisfaction\")\n",
    "plt.title(\"Balance between satisfied and unsatisfied or neutral\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877f18d-53c9-4d91-9658-60bc805a944b",
   "metadata": {},
   "source": [
    "We next create a Feature Correlation Matrix, which allows us to evaluate the direction as well as the strength of a relationship between variables. Look at the huge correlation between Departure Delay vs Arrival Delay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da5c2e-13be-4765-aea2-06eca853e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(airlines_df.corr(), dtype=np.bool_)\n",
    "mask[np.triu_indices_from(mask)]= True\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.rcParams['font.size'] = '12'\n",
    "plt.title(\"Feature Correlation Matrix\", fontsize=20)\n",
    "sns.heatmap(airlines_df.corr(), annot=True, mask=mask, linewidths=.5, vmin=-1, vmax=1, fmt=\".2f\", cmap='coolwarm');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0043004-60c8-4774-8684-6d5110b7a527",
   "metadata": {},
   "source": [
    "Don’t get out of your seats just yet! The seatbelt sign is still on! We turn on the In-flight entertainment system to view our Interactive EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007542f-c2ed-4be5-b69e-8e87a7a7e7a9",
   "metadata": {},
   "source": [
    "## Interactive EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d70721-452a-45ec-bae9-b7aa5a96f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a datagrid\n",
    "grid = ipydatagrid.DataGrid(airlines_df)\n",
    "\n",
    "# Some theming to add some color\n",
    "cotton_candy = {\n",
    "    \"background_color\": \"rgb(255, 245, 251)\",\n",
    "    \"header_background_color\": \"rgb(207, 212, 252, 1)\",\n",
    "    \"header_grid_line_color\": \"rgb(0, 247, 181, 0.9)\",\n",
    "    \"vertical_grid_line_color\": \"rgb(0, 247, 181, 0.3)\",\n",
    "    \"horizontal_grid_line_color\": \"rgb(0, 247, 181, 0.3)\",\n",
    "    \"selection_fill_color\": \"rgb(212, 245, 255, 0.3)\",\n",
    "    \"selection_border_color\": \"rgb(78, 174, 212)\",\n",
    "    \"header_selection_fill_color\": \"rgb(212, 255, 239, 0.3)\",\n",
    "    \"header_selection_border_color\": \"rgb(252, 3, 115)\",\n",
    "    \"cursor_fill_color\": \"rgb(186, 32, 186, 0.2)\",\n",
    "    \"cursor_border_color\": \"rgb(191, 191, 78)\",\n",
    "}\n",
    "\n",
    "grid.grid_style = cotton_candy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363d74d-ac4f-4e8e-b6cd-708e0418b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define widgets and variables\n",
    "numerical_cols = airlines_df.select_dtypes([int, float]).columns.tolist()\n",
    "age_range = (airlines_df['Age'].min(), airlines_df['Age'].max())\n",
    "columns_index = {k:grid._column_name_to_index(k) + 1 for k in airlines_df.columns}\n",
    "range_slider = widgets.IntRangeSlider(min=age_range[0], max=age_range[1], value=age_range, description=\"Age Range\")\n",
    "gender_dropdown = widgets.Dropdown(options=airlines_df['Gender'].unique().tolist() + [\"Both\"], \n",
    "                                   value=\"Both\", layout={\"width\":\"200px\"}, description=\"Gender\")\n",
    "scatter_x_dropdown = widgets.Dropdown(options=numerical_cols, \n",
    "                                      value=numerical_cols[2], layout={\"width\":\"250px\"}, description=\"Scatter X-Axis\")\n",
    "scatter_y_dropdown = widgets.Dropdown(options=numerical_cols, value=numerical_cols[1], \n",
    "                                      layout={\"width\":\"250px\"}, description=\"Scatter Y-Axis\")\n",
    "\n",
    "# Chart\n",
    "sc_x = bqp.LinearScale()\n",
    "sc_y = bqp.LinearScale()\n",
    "scatt = bqp.ScatterGL(\n",
    "    x=airlines_df[scatter_x_dropdown.value].values,\n",
    "    y=airlines_df[scatter_y_dropdown.value].values,\n",
    "    names=np.arange(10),\n",
    "    scales={\"x\": sc_x, \"y\": sc_y},\n",
    "    colors=[\"limegreen\", \"purple\"],\n",
    ")\n",
    "ax_x = bqp.Axis(scale=sc_x, label=scatter_x_dropdown.value)\n",
    "ax_y = bqp.Axis(scale=sc_y, orientation=\"vertical\", tick_format=\"d\", label=scatter_y_dropdown.value)\n",
    "fig = bqp.Figure(marks=[scatt], axes=[ax_x, ax_y], padding_x=0.025, interaction=bqp.interacts.PanZoom(scales={'x': [sc_x], 'y': [sc_y]}),\n",
    "                 title=\"Select axes from the dropdown boxes!\")\n",
    "\n",
    "\n",
    "# Event handlers\n",
    "def filter_gender(e):\n",
    "    with grid.hold_sync():\n",
    "        selected_gender = e.get(\"new\")\n",
    "        if selected_gender == \"Both\":\n",
    "            grid._transforms = list(filter(lambda x: x['columnIndex'] != columns_index.get(\"Gender\"), grid._transforms))\n",
    "            return \n",
    "\n",
    "        grid.transform([\n",
    "            {\"type\": \"filter\", \"operator\": \"=\", \"columnIndex\": columns_index.get(\"Gender\"), \"value\": selected_gender},\n",
    "            {'type': 'filter', 'columnIndex': columns_index.get(\"Age\"), 'operator': 'between', 'value': range_slider.value}\n",
    "        ])\n",
    "        update_scatter_chart(None)\n",
    "    \n",
    "def filter_age(e):\n",
    "    with grid.hold_sync():\n",
    "        age_tuple = e.get(\"new\")\n",
    "        grid.transform([\n",
    "            {'type': 'filter', 'columnIndex': columns_index.get(\"Age\"), 'operator': 'between', 'value': age_tuple}\n",
    "        ])\n",
    "        update_scatter_chart(None)\n",
    "    \n",
    "def update_scatter_chart(e):\n",
    "    with scatt.hold_sync():\n",
    "        data = grid.get_visible_data()\n",
    "        scatt.x = data[scatter_x_dropdown.value].values\n",
    "        scatt.y = data[scatter_y_dropdown.value].values\n",
    "        sc_x.min = float(data[scatter_x_dropdown.value].min())\n",
    "        sc_x.max = float(data[scatter_x_dropdown.value].max())\n",
    "        sc_y.min = float(data[scatter_y_dropdown.value].min())\n",
    "        sc_y.max = float(data[scatter_y_dropdown.value].max())\n",
    "        ax_x.label = scatter_x_dropdown.value\n",
    "        ax_y.label = scatter_y_dropdown.value\n",
    "        fig.title = f\"{scatter_x_dropdown.value} vs. {scatter_y_dropdown.value}\"\n",
    "    \n",
    "    \n",
    "gender_dropdown.observe(filter_gender, names=['value'])\n",
    "range_slider.observe(filter_age, names=['value'])\n",
    "scatter_x_dropdown.observe(update_scatter_chart, names=[\"value\"])\n",
    "scatter_y_dropdown.observe(update_scatter_chart, names=[\"value\"])\n",
    "\n",
    "\n",
    "# Rendering the grid and widgets\n",
    "widgets.VBox([\n",
    "    widgets.HTML(value=\"<h1>Airline Passengers Data Explorer</h1>\"),\n",
    "    widgets.HBox([\n",
    "        range_slider, gender_dropdown, scatter_x_dropdown, scatter_y_dropdown\n",
    "    ], layout=widgets.Layout(flex='1 1 auto', width='100%')),\n",
    "    grid,\n",
    "    fig\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1c9c4-a2b1-4e65-8360-14451c6dbd77",
   "metadata": {},
   "source": [
    "## III. In-Flight (Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c264ceb9-eb97-4542-b8e7-ec5a29ad71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f57c0-406e-4d54-99bd-ca3f961a73cb",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">Before we start train/test splitting, we need to reason about the kind of analysis we want to do, and whether the data, in its current form, is suitable.\n",
    "The obvious target for this dataset, given we're dealing with passenger satisfaction with a given airline, would be to to predict whether a potential\n",
    "passenger would be satisfies or neutral/unsatisfied given some paramaters like their age, sex, travel class, flight delay etc.</span>\n",
    "\n",
    "<span style=\"font-weight: bold;\">This type of analysis lends itself nicely to Logistic Regression, which could be the ideal model to use for this analysis, with this dataset.\n",
    "To use logistic regression, we are likely going to need to One-Hot Encode categorical series so they're represented as numbers.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51277b04-c03a-4f3c-bf0f-602b3a35f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4439fa-58fe-4b4b-bbb5-b3ee0c613453",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">It's possible to see that we have quite a few columns which contain categorical data, with them ost crucial column being the predicted column.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb4d33-c8bd-4574-8463-ab1acdc82eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with categorical data\n",
    "airlines_df.select_dtypes([\"object\"]).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e066d216-11b4-48e6-af8e-4a4e035a430d",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">Below, we create a new dataframe which has all categorical values encoded to integers. We will use that dataframe to train and test our models.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a92c2-bf6f-4f5e-8f19-eb2239df9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Function to retrieve the string to integer mapping used in One-Hot encoding\n",
    "def get_encoding_mapping(encoded_series, types):\n",
    "    return dict(zip(encoded_series.classes_, encoded_series.transform(types)))\n",
    "\n",
    "# Creating a copy of the airlines dataframe, as we will encode and replace \n",
    "# categorical columns with their numerical equivalents\n",
    "airlines_df_encoded = airlines_df.copy()\n",
    "\n",
    "# Mapping dictionary to convert back from encoding to string - will be used later!\n",
    "enc_mappings = []\n",
    "\n",
    "for col in airlines_df_encoded.select_dtypes([\"object\"]).columns:\n",
    "    # One-Hot encoding categorical columns\n",
    "    cur_series = airlines_df_encoded[col]\n",
    "    col_enc = LabelEncoder()\n",
    "    col_enc.fit(cur_series)\n",
    "    col_unique_vals = cur_series.unique().tolist()\n",
    "    enc_mappings.append(get_encoding_mapping(col_enc, col_unique_vals))\n",
    "    airlines_df_encoded[col] = col_enc.transform(cur_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a40e3db-b5f9-4e0f-9655-04a6841192a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the conversion succeeded\n",
    "airlines_df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16772f5a-1aa8-4adf-8c26-a08bf66c7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'ID' columns is unlikely to be useful for our model, so we will drop it.\n",
    "airlines_df_encoded = airlines_df_encoded.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b41d8f-9758-4db7-b982-aba233aa51f1",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">Our data is now in the right shape to be used as an input to a ML model! Recall that some columns had very high positive/negative correlation. We should keep an eye on those and potentially drop some of them as inputs so that we reduce the amount of multicollinearity in the model.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81461d-2ded-497b-8924-2e011d381a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns used to predict \"Satisfaction\"\n",
    "feature_list = list(filter(lambda x: x != 'Satisfaction', airlines_df_encoded.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f6a57-c2d4-43a9-a58b-da01dc6e7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regressor and regressand\n",
    "y = airlines_df_encoded[['Satisfaction']]\n",
    "X = airlines_df_encoded[feature_list]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31069496-769e-4f52-b9ac-5648441d5630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check everything looks okay\n",
    "display(X_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360420b-668f-40d4-bfeb-64d45e76b238",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">We're ready to instantiate and fit our model now! But before we do that, it would be good to define a helper function which can standardise the way we fit, train and score our models. This will reduce code duplication and the potential for operational.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265206f-90e9-4864-be6d-2f9f83a39ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "def run_model(model, X_train, X_test, y_train, y_test, print_results=True):\n",
    "    # Convert to 1D arrays as some of the sklearn functions require them    \n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "    \n",
    "    # Fit our and train our model     \n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred) \n",
    "    cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "    if print_results:\n",
    "        print(f\"Accuracy:{accuracy}, ROC AUC: {roc_auc}\")\n",
    "        print(classification_report(y_test,y_pred,digits=5))\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 7))\n",
    "        cmd = ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, ax=ax1)\n",
    "        rocd = RocCurveDisplay.from_estimator(model, X_test, y_test, ax=ax2)\n",
    "    \n",
    "    return model, accuracy, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1be60-4d0d-49dd-aff4-41c22490c97d",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">We can also add a function for inspecting the regression coefficients for LogisticRegression, so we can get more insight about the relevance of our features. This function is defined below.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f24853-a11b-4e4c-8a57-b87a562969aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def infer_logistic_regression_coefs(y_train, X_train):\n",
    "    logit_model = sm.Logit(y_train, X_train)\n",
    "    result = logit_model.fit()\n",
    "    print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9993758-a7d0-46e4-b283-cadcf9b10346",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d16bdb-38a7-45d8-9786-4d9d53159f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Running our model (using a higher number of iteration to maximize chance of model convergence)\n",
    "lg_model, lg_accuracy, lg_roc_auc = run_model(LogisticRegression(max_iter=4000), X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab20a61-a402-4fc9-82e7-a9787bfb8a07",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">Some additional statistics. Looking into the regression model and determining which features are important and affect our regression.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4400091d-8e20-4c99-9af9-e7559cc06b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_logistic_regression_coefs(y_train, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf9957c-c10a-423c-84d3-4f27b6160f40",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">Let's add regularization. We will start with L1 ratio of 1, which means we're looking at full Lasso regression. In scikit-learn, ElsticNet regularized logistic regression must be performed using the \"saga\" solver.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5451c93-d5a6-415b-9db5-e7eba374f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, accuracy, roc_auc = run_model(LogisticRegression(penalty=\"elasticnet\", l1_ratio=0.5, solver=\"saga\"), X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ee02b-3643-4b1a-980f-af6f8fa897cb",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">We were able to use the 'saga' solver in order to add a regularization term, but we can see the <span style='color:red'>warning</span> indicating the solver wasn't able to converge. This is because logistic regression models with regularization are not scale invariant! We can improve the proformance of the 'saga' solver by standardizing the input. Let's do that below!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4075f627-8e0c-442b-9e43-93ecdce7e8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model, accuracy, roc_auc = run_model(Pipeline([('scaler', StandardScaler()), ('logistic', LogisticRegression(penalty=\"elasticnet\", l1_ratio=1, solver=\"saga\"))]), X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76b35a-ed15-443c-ac26-0bd5326448fe",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">The solver is able to converge and we're getting a better result compared to the cell above. But the score is roughly the same as the score of the model without regularization. Let's run a grid search to see if tweaking the l1 ratio can help up achieve better performance.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0fd0b-1fcf-42ce-8319-5d79d779e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\"logistic__l1_ratio\": np.arange(0,1.1,0.1)}\n",
    "\n",
    "gcv = GridSearchCV(estimator=Pipeline([('scaler', StandardScaler()), ('logistic', LogisticRegression(penalty=\"elasticnet\", solver=\"saga\"))]), param_grid=parameters, n_jobs=4)\n",
    "gcv.fit(X_train, y_train.values.ravel())\n",
    "print(f\"Best L1 regularization rario parameter: {gcv.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b01f3-e5c0-4b7d-a23b-761920c474d4",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold;\">It turns out that our chosen parameter L1 ratio parameter is the best choice for the model. In other words, a full Lasso regression seems to perform better than a mix of, or only Ridge regression.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d340c2-841f-4df4-abed-93b334ae753f",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f741f12-6217-47a6-a799-ba2b43c8a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model, accuracy, roc_auc = run_model(GaussianNB(), X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf16e221-e1ed-4773-a699-182957aef127",
   "metadata": {},
   "source": [
    "#### K-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c49a7b6-fc92-415d-ac36-e8df738f5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model, accuracy, roc_auc = run_model(KNeighborsClassifier(n_neighbors=10, algorithm=\"kd_tree\", n_jobs=4), X_train, X_test, y_train, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0175d6-6d6d-48cd-8a63-be2a6ebaf066",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034f6f5-3983-472e-a240-ee4df5498376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model, accuracy, roc_auc = run_model(DecisionTreeClassifier(max_depth=5, random_state=0, max_leaf_nodes=10), X_train, X_test, y_train, y_test, True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ec6d0-8a3b-4241-b96c-a34f2286f880",
   "metadata": {},
   "source": [
    "We can visualize the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd7eef-280f-40e6-b1fc-c4b2cb708d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "plt.figure(figsize=(16,9), dpi=120)\n",
    "tree.plot_tree(model, label='all', feature_names=feature_list, fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eadb88-7db5-4b12-a896-b341bce0482f",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25602d-2e09-4289-9f33-b60ecaa6c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model, accuracy, roc_auc = run_model(MLPClassifier(), X_train, X_test, y_train, y_test, True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36981964-f283-4ee4-98d2-18aecef30d1b",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3661e-9727-43f8-9741-0e64044e8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model, accuracy, roc_auc = run_model(RandomForestClassifier(), X_train, X_test, y_train, y_test, True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00ef046-c0a4-4722-9600-82c1ebc3042d",
   "metadata": {},
   "source": [
    "#### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae1ab9-bcf2-4ac1-ac84-6c0752004482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model, accuracy, roc_auc = run_model(AdaBoostClassifier(), X_train, X_test, y_train, y_test, True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57108f7-69ba-46f5-8b98-cc1c18c42416",
   "metadata": {},
   "source": [
    "## V: Arrival"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9977744a-ed33-4630-bcf3-b0db337889f1",
   "metadata": {},
   "source": [
    "We have reached the end of our flight towards data exploration and modeling. \n",
    "We hope you had an enjoyable journey. Godspeed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d35f7-1d18-47d4-a8cf-c76d3834e7ce",
   "metadata": {},
   "source": [
    "## IV: Landing (Description of challenges/obstacles faced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14749d-8e2a-4be2-a40e-ee6bb3eb1106",
   "metadata": {},
   "source": [
    "We have reached the end of our flight towards data exploration and modeling. \n",
    "We hope you had an enjoyable journey. Godspeed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
